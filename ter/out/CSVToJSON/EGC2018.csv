Id_article;series;booktitle;year;title;abstract;authors;pdf1page;pdfarticle;MS;place;Latitude;Longitude
1260;Revue des Nouvelles Technologies de l'Information;EGC;2018;#Idéo2017 : une plateforme citoyenne dédiée à l'analyse des tweets lors des événements politiques;Cette plateforme a pour objectif de permettre aux citoyens d'analyserpar eux-mêmes les tweets politiques lors d'événements spécifiques en France.Pour le cas de l'élection présidentielle de 2017, #Idéo2017 analysait en quasitemps réel les messages des candidats, et fournissait leurs principales caractéristiques,l'usage du lexique politique et des comparaisons entre les candidats.;Claudia Marinica, Julien Longhi, Nader Hassine, Abdulhafiz Alkhouli, Boris Borzic;http://editions-rnti.fr/render_pdf.php?p1&p=1002425;http://editions-rnti.fr/render_pdf.php?p=1002425;11;Paris;48.8534;2.3488
1261;Revue des Nouvelles Technologies de l'Information;EGC;2018;A two level co-clustering algorithm for very large data sets;La classification croisée (co-clustering) est une technique qui permet d'extraire la structuresous-jacente existante entre les lignes et les colonnes d'une table de données sous forme de blocs. Plusieurs applications utilisent cette technique, cependant de nombreux algorithmes de co-clustering actuels ne passent pas à l'échelle. Une des approches utilisées avec succès est la méthode MODL, qui optimise un critère de vraisemblance régularisée. Cependent, pour des tailles plus importante, cette méthode atteint sa limite. Dans cet article, nous présentons un nouvel algorithme de co-clustering à deux niveaux, qui compte tenu du critère MODL permet de traiter efficacement de données de très grande taille, ne pouvant pas tenir en mémoire. Nos expériences montrent que l'approche proposée gagne en temps de calcul tout en produisant des solutions de qualité.;Marius Barctus, Marc Boullé, Fabrice Clérot;http://editions-rnti.fr/render_pdf.php?p1&p=1002372;http://editions-rnti.fr/render_pdf.php?p=1002372;8;Paris;48.8535;2.3489
1262;Revue des Nouvelles Technologies de l'Information;EGC;2018;ALGeoSPF: Un modèle de factorisation basé sur du clustering géographique pour la recommandation de POI;La recommandation de points d'intérêts est devenue une caractéristiqueessentielle des réseaux sociaux géo-localisés qui a accompagnél'émergence des échanges massifs de données digitales. Cependantles faibles densités de points d'intérêts visités par les utilisateurs rendentle problème difficile à traiter, d'autant plus que les espaces de mobilitédes utilisateurs sont très hétérogènes, allant de la ville au monde entier.Dans ce papier nous explorons l'impact d'une approche de clusteringspatial sur la qualité de la recommandation. Notre approche est baséesur un modèle de factorisation de matrices de Poisson et un réseau socialinféré des différents comportements de mobilité. Nous avons conduitune évaluation comparative des performances de notre approche sur unjeu de données réaliste. Les résultats expérimentaux montrent que notreapproche permet une précision supérieure aux techniques de recommandationalternatives.;Jean-Benoît Griesner, Talel Abdesssalem, Hubert Naacke, Pierre Dosne;http://editions-rnti.fr/render_pdf.php?p1&p=1002380;http://editions-rnti.fr/render_pdf.php?p=1002380;3;Paris;48.8536;2.3490
1263;Revue des Nouvelles Technologies de l'Information;EGC;2018;Analyse des sentiments à partir des commentaires Facebook publiés en Arabe standard ou dialectal marocain par une approche d'apprentissage automatique;L'analyse des sentiments est un processus pendant lequel la polarité(positive, négative ou neutre) d'un texte donné est déterminée. Nous nous intéressonsdans ce travail à l'analyse des sentiments à partir des commentairesFacebook, réels, partagés en arabe standard ou dialectal marocain par une approchebasée sur l'apprentissage automatique. Ce processus commence par lacollecte des commentaires et leur annotation à l'aide du crowdsourcing suivid'une phase de prétraitement du texte afin d'extraire des mots arabes réduits àleur racine. Ces mots vont être utilisés pour la construction des variables d'entréeen utilisant plusieurs combinaisons de schémas d'extraction et de pondération.Pour réduire la dimensionnalité, une méthode de sélection de variables est appliquée.Les résultats obtenus des expérimentations sont très prometteurs.;Abdeljalil Elouardighi, Mohcine Maghfour, Hafdalla Hammia, Fatima-Zahra Aazi;http://editions-rnti.fr/render_pdf.php?p1&p=1002397;http://editions-rnti.fr/render_pdf.php?p=1002397;7;Paris;48.8537;2.3491
1264;Revue des Nouvelles Technologies de l'Information;EGC;2018;Analyse en rôles sémantiques pour le résumé automatique;"Cet article présente une approche visant à extraire les informations expriméesdans un corpus de textes et en produire un résumé. Plusieurs variantes deméthodes extractives de résumé de texte ont été implémentées et évaluées. Leurprincipale originalité réside dans l'exploitation de structures appelées CDS (pourClause Description Structure) issues d'un composant d'annotation en rôles sémantiqueset non directement des phrases composant les textes. Le résumé obtenuest un sous-ensemble des CDS issus du corpus d'origine ; ce format permettradans la suite la détection d'incohérences textuelles. Dans ce travail, nous retransformonsles CDS résumés en texte pour permettre la comparaison de notreapproche avec celles de la littérature. Les premiers résultats sont très encourageants: les variantes que nous proposons obtiennent généralement de meilleursscores que des implémentations de méthodes de référence.";Elyase Lassouli, Yasmine Mesbahi, Camille Pradel, Damien Sileo;http://editions-rnti.fr/render_pdf.php?p1&p=1002384;http://editions-rnti.fr/render_pdf.php?p=1002384;1;Paris;48.8538;2.3492
1265;Revue des Nouvelles Technologies de l'Information;EGC;2018;Analyse Ontologique de scénario dans un contexte Big Data;;Marwan Batrouni, Aurélie Bertaux, Christophe Nicolle;http://editions-rnti.fr/render_pdf.php?p1&p=1002414;http://editions-rnti.fr/render_pdf.php?p=1002414;11;Paris;48.8539;2.3493
1266;Revue des Nouvelles Technologies de l'Information;EGC;2018;Apport de la fouille de données pour la prévention du risque suicidaire;Avec plus de 800 000 décès par an dans le monde, le suicide est latroisième cause de décès évitable. Il y a 20 fois plus de tentatives, impliquant denombreuses hospitalisations, des coûts humains et sociétaux énormes. Ces dernièresannées, les modalités de collecte de données, sociologiques et cliniques,concernant les patients reçus en consultation après une tentative, ont connu deprofonds changements liés aux outils numériques. Nous présentons les principauxrésultats d'un processus complet de fouille de données sur un échantillonde suicidants de deux hôpitaux européens. Le premier objectif est d'identifierdes groupes de patients similaires et le second d'identifier des facteurs de risqueassociés au nombre de tentatives. Des méthodes non supervisées (ACM et clustering)et supervisées (arbres de régression) sont appliquées pour y répondre.Les résultats mettent en lumière l'apport de la fouille de données à des fins descriptivesou explicatives.;Romain Billot, Sofian Berrouiguet, Mark Larsen, Michel Walter, Jorge López Castroman, Enrique Baca-García, Philippe Courtet, Philippe Lenca;http://editions-rnti.fr/render_pdf.php?p1&p=1002376;http://editions-rnti.fr/render_pdf.php?p=1002376;5;Paris;48.8540;2.3494
1267;Revue des Nouvelles Technologies de l'Information;EGC;2018;Apport des modèles locaux pour les K-moyennes prédictives;Dans le cadre du clustering prédictif, pour attribuer la classe aux groupesformés à la fin de la phase d'apprentissage, le vote majoritaire est la méthodecommunément utilisée. Cependant, cette approche comporte certaines limitationsqui influent directement sur la qualité des résultats obtenus en termes deprédiction. Pour surmonter ce problème, nous proposons d'incorporer des modèlesprédictifs localement dans les clusters formés afin d'améliorer la qualitéprédictive du modèle global. Les résultats expérimentaux montrent que cette incorporationpermet d'obtenir des résultats (en termes de prédiction) significativementmeilleurs par rapport à ceux obtenus en utilisant le vote majoritaire ainsique des résultats très compétitifs avec ceux obtenus par des algorithmes performantsd'apprentissage supervisé “similaires”. Ceci est effectué sans dégrader lepouvoir descriptif (explicatif) du modèle global.;Vincent Lemaire, Oumaima Alaoui Ismaili;http://editions-rnti.fr/render_pdf.php?p1&p=1002379;http://editions-rnti.fr/render_pdf.php?p=1002379;2;Paris;48.8541;2.3495
1268;Revue des Nouvelles Technologies de l'Information;EGC;2018;Apprendre les relations de préférence et de co-occurrence entre les labels en classification multi-labels;En classification multi-labels, chaque instance est associée àun ou plusieurs labels. Par exemple, un morceau de musique peut êtreassocié aux labels 'heureux' et 'relaxant'. Des relations de co-occurrencepeuvent exister entre les labels : par exemple, les labels 'heureux' et 'triste'ne peuvent pas être associés au même morceau de musique. Les labelspeuvent aussi avoir des relations de préférence : par exemple, pour un morceaude musique contenant plusieurs piques, le label 'heureux' est préférépar rapport au label 'relaxant'. Les relations entre les labels peuvent aiderà mieux prédire les labels associés aux instances. Les approches existantespeuvent apprendre soit les relations de co-occurrence, soit les relationsde préférence. Ce travail introduit une approche permettant de combinerl'apprentissage des deux types de relations. Les expérimentations menéesmontrent que la nouvelle approche introduite offre les meilleurs résultatsde prédiction par rapports à cinq approches de l'état de l'art.;Khalil Laghmari, Christophe Marsala, Mohammed Ramdani;http://editions-rnti.fr/render_pdf.php?p1&p=1002381;http://editions-rnti.fr/render_pdf.php?p=1002381;2;Paris;48.8542;2.3496
1269;Revue des Nouvelles Technologies de l'Information;EGC;2018;Approche contextuelle par régression pour les tests A/B;Les tests A/B sont des procédures utilisées par les entreprises du webet de la santé entre autres, pour mesurer l'impact d'un changement de versiond'une variable par rapport à un objectif. Bien qu'un nombre de plus en plusimportant de données soit disponible, la mise en place concrète d'un tel testpeut impliquer un coût important relatif à l'observation et à l'évaluation d'unevariation lorsque celle-ci n'est pas optimale.Dans ce papier, nous présentons une nouvelle approche intégrant le principed'un bandit contextuel prenant en compte ces variables via une procédure destratification.;Emmanuelle Claeys, Pierre Gançarski, Myriam Maumy-Bertrand;http://editions-rnti.fr/render_pdf.php?p1&p=1002387;http://editions-rnti.fr/render_pdf.php?p=1002387;2;Paris;48.8543;2.3497
1270;Revue des Nouvelles Technologies de l'Information;EGC;2018;Big Data for understanding human dynamics: the power of networks;;Fosca Giannotti;http://editions-rnti.fr/render_pdf.php?p1&p=1002363;http://editions-rnti.fr/render_pdf.php?p=1002363;0;Paris;48.8544;2.3498
1271;Revue des Nouvelles Technologies de l'Information;EGC;2018;Cartes Auto-Organisatrices Incrémentales appliquées au Clustering Collaboratif;Le Clustering Collaboratif (CC) vise à faire ressortir les structurescommunes présentes dans plusieurs vues indépendantes en se basant sur unepremière étape de clustering locale, effectuée dans notre cas à l'aide de CartesAuto-Organisatrices (SOM pour Self Organizing Maps en anglais). Pour faireface à la quantité toujours croissante de données disponibles, l'utilisation de méthodesde clustering incrémentales est devenue nécessaire. Ce papier présente unalgorithme de SOM incrémentales compatibles avec les contraintes du CC. Lesexpérimentations conduites sur plusieurs jeux de données démontrent la validitéde cette méthode et présentent l'influence de la taille du batch utilisé lors del'apprentissage.;Denis Maurel, Jérémie Sublime, Sylvain Lefebvre;http://editions-rnti.fr/render_pdf.php?p1&p=1002418;http://editions-rnti.fr/render_pdf.php?p=1002418;2;Paris;48.8545;2.3499
1272;Revue des Nouvelles Technologies de l'Information;EGC;2018;Catégorisation d'articles scientifiques basée sur les relations sémantiques des mots-clés;;Bastien Latard, Jonathan Weber, Germain Forestier, Michel Hassenforder;http://editions-rnti.fr/render_pdf.php?p1&p=1002406;http://editions-rnti.fr/render_pdf.php?p=1002406;11;Paris;48.8546;2.3500
1273;Revue des Nouvelles Technologies de l'Information;EGC;2018;Classification de Données Complexes par Globalisation de Mesures de Similarité via les Moyennes Quasi-Arithmétiques;La plupart des méthodes de classification sont conçues pour des types particuliers de données: données numériques, textuelles, catégoriques, fonctionnelles, probabilistes ou encore de type graphes. Cependant, les données générées dans notre quotidien sont en général composées de données de types mixtes. Par exemple, si nous considérons la prévention cardiaque dans le domaine de la santé, les applications vont combiner des données issues de capteurs avec d'autres données telles que l'âge, le niveau d'effort, la fréquence cardiaque maximale, des histogrammes de fréquences cardiaques moyennes lors de précédents efforts, etc. Ceci nous amène à la problématique de construire des classes en tenant compte de ces différentes données, et de définir une mesure de similarité à partir des similarités de paires d'objets sur les différents types de variables. Dans cet article nous proposons une méthode de classification basée sur la fusion des matrices de similarité à l'aide des moyennes quasi-arithmétiques qui permet de choisir les différentes “dimensions” des données à considérer, et ce quel que soit le type de données, pour autant qu'une mesure, de similarité ou de dissimilarité existe pour chacun des types de données, ce qui est très souvent le cas.;Étienne-Cuvelier, Marie-Aude-Aufaure;http://editions-rnti.fr/render_pdf.php?p1&p=1002368;http://editions-rnti.fr/render_pdf.php?p=1002368;2;Paris;48.8547;2.3501
1274;Revue des Nouvelles Technologies de l'Information;EGC;2018;Community structure in complex networks;;Santo Fortunato;http://editions-rnti.fr/render_pdf.php?p1&p=1002362;http://editions-rnti.fr/render_pdf.php?p=1002362;0;Paris;48.8548;2.3502
1275;Revue des Nouvelles Technologies de l'Information;EGC;2018;Comparaison de mesures de centralité basées sur les plus courts chemins dans les réseaux dynamiques;Définir l'importance des noeuds dans les réseaux statiques est unequestion de recherche très étudiée depuis de nombreuses années. Dernièrement,des adaptations des métriques classiques ont été proposées pour les réseaux dynamiques.Ces méthodes reposent sur des approches très différentes dans leurfaçon d'évaluer l'importance des noeuds à un instant donné. Il est donc nécessairede pouvoir les évaluer et les comparer. Dans cet article, nous comparonstrois approches existes pour mieux comprendre ce qui les différencie. Nous montronsque la nature des jeux de données influe grandement sur le comportementdes méthodes, et que pour certains d'entre eux, la notion d'importance n'est pastoujours pertinente.;Marwan Ghanem, Clémence Magnien, Fabien Tarissan;http://editions-rnti.fr/render_pdf.php?p1&p=1002416;http://editions-rnti.fr/render_pdf.php?p=1002416;7;Paris;48.8549;2.3503
1276;Revue des Nouvelles Technologies de l'Information;EGC;2018;Complémentarités de représentations vectorielles pour la similarité sémantique;La tâche de similarité sémantique textuelle consiste à exprimer automatiquementun nombre reflétant la similarité sémantique de deux fragmentsde texte. Chaque année depuis 2012, les campagnes de SemEval déroulent cettetâche de similarité sémantique textuelle. Cet article présente une méthode associantdifférentes représentations vectorielles de phrases dans l'objectif d'améliorerles résultats obtenus en similarité sémantique. Notre hypothèse est que différentesreprésentations permettraient de représenter différents aspects sémantiques,et par extension, d'améliorer les similarités calculées, la principale difficultéétant de sélectionner les représentations les plus complémentaires pourcette tâche. Notre système se base sur le système vainqueur de la campagne de2015 ainsi que sur notre méthode de sélection par complémentarité. Les résultatsobtenus viennent confirmer l'intérêt de cette méthode lorsqu'ils sont comparésaux résultats de la campagne de 2016.;Julien Hay, Tim Van de Cruys, Philippe Muller, Bich-Liên Doan, Fabrice Popineau, Lyes Benamsili;http://editions-rnti.fr/render_pdf.php?p1&p=1002378;http://editions-rnti.fr/render_pdf.php?p=1002378;8;Paris;48.8550;2.3504
1277;Revue des Nouvelles Technologies de l'Information;EGC;2018;Contextualisation de Singularités en Temps-Réel par Extraction de Connaissances du Web des Données;L'émergence de l'IoT et du traitement en temps-réel oblige les entreprises à considérer la détection d'anomalies comme un élément clé de leur activité. Afin de garantir une haute précision dans le processus de détection, des métadonnées fournissant un contexte spatio-temporel sur les mesures des capteurs sont nécessaires. Dans cet article, nous présentons un système générique qui aide à capturer, analyser, qualifier et stocker les informations contextuelles d'un domaine d'application donné. L'approche proposée est basée sur des méthodes sémantiques qui exploitent des ontologies pour évaluer la pertinence de l'information contextuelle. Après une description des composants principaux de l'architecture, la performance et la pertinence du système sont démontrées par une évaluation sur des ensembles de données du monde réel.;Badre Belabbess, Jérémy Lhez, Musab Bairat, Olivier Curé;http://editions-rnti.fr/render_pdf.php?p1&p=1002369;http://editions-rnti.fr/render_pdf.php?p=1002369;1;Paris;48.8551;2.3505
1278;Revue des Nouvelles Technologies de l'Information;EGC;2018;Contraintes prescriptives compatibles avec OWL2-ER pour évaluer la complétude d'ontologies;L'article définit les contraintes prescriptives comme des règles permettant aux moteurs d'inférence de vérifier que certains objets formels sont réellement utilisés – pas seulement inférés – ou non, dans certaines conditions. Il montre que ces contraintes nécessitent de ne pas exploiter de mécanisme d'héritage (ou autres mécanismes ajoutant des relations à des objets) durant les tests des conclusions des règles. Il donne une méthode générale pour effectuer cela et des commandes SPARQL pour implémenter cette méthode lorsque les règles sont représentées via des relations sous-classe-de entre conditions et conclusions. L'article illustre ces commandes avec la vérification de patrons de conception d'ontologies. Plus généralement, l'approche peut être utilisée pour vérifier la complétude d'une ontologie, ou représenter dans une ontologie (plutôt que par des requêtes ou des procédures ad hoc) des contraintes permettant de calculer un degré de complétude d'ontologie. L'approche peut ainsi aider l'élicitation, la modélisation ou la validation de connaissances.;Philippe Martin, Jun Jo;http://editions-rnti.fr/render_pdf.php?p1&p=1002366;http://editions-rnti.fr/render_pdf.php?p=1002366;1;Paris;48.8552;2.3506
1279;Revue des Nouvelles Technologies de l'Information;EGC;2018;Contribution à l'étude de la distributivité d'un treillis de concepts;Nous nous intéressons aux treillis distributifs dans le cadre de l'analyse formelle de concepts (FCA). La motivation primitive vient de la phylogénie et des graphes médians pour représenter les dérivations biologiques et les arbres parcimonieux. La FCA propose des algorithmes efficaces de construction de treillis de concepts. Cependant, un treillis de concepts n'est pas en correspondance avec un graphe médian sauf s'il est distributif, d'où l'idée d'étudier la transformation d'un treillis de concepts en un treillis distributif. Pour ce faire, nous nous appuyons sur le théorème de représentation de Birkhoff qui nous permet de systématiser la transformation d'un contexte quelconque en un contexte de treillis de concepts distributif. Ainsi, nous pouvons bénéficier de l'algorithmique de FCA pour construire mais aussi visualiser les treillis de concepts distributifs, et enfin étudier les graphes médians associés.;Alain Gély, Miguel Couceiro, Yassine Namir, Amedeo Napoli;http://editions-rnti.fr/render_pdf.php?p1&p=1002373;http://editions-rnti.fr/render_pdf.php?p=1002373;3;Paris;48.8553;2.3507
1280;Revue des Nouvelles Technologies de l'Information;EGC;2018;Découverte de motifs graduels partiellement ordonnés : application aux données d'expériences scientifiques;Les données séquentielles sont aujourd'hui omniprésentes etconcernent divers domaines d'application. La fouille de données de séquencespermet d'extraire des informations et des connaissances pouvant être à forte valeurajoutée. Cependant, lorsque les données de séquences sont riches en donnéesnumériques, des méthodes de fouille de données plus fines sont nécessairespour extraire des connaissances plus expressives représentant la variabilité desvaleurs numériques ainsi que leur éventuelle interdépendance. Dans cet article,nous présentons une nouvelle méthode de découverte de séquences graduellesfréquentes représentées par des graphes à partir d'une source de données de séquencesen RDF (Resource Description Framework 1). Ces dernières sont transforméesen graphes graduels partiellement ordonnés, gpo. Nous proposons unalgorithme permettant de découvrir les sous-graphes gpo fréquents. Une expérimentationsur deux jeux de données réelles ont montré la faisabilité et la pertinencede notre approche.;Simon Ser, Fatiha Saïs, Maguelonne Teisseire;http://editions-rnti.fr/render_pdf.php?p1&p=1002382;http://editions-rnti.fr/render_pdf.php?p=1002382;1;Paris;48.8554;2.3508
1281;Revue des Nouvelles Technologies de l'Information;EGC;2018;Définir les catégories de DBpédia avec des règles d'associations et des redescriptions;DBpédia, qui encode les connaissances de Wikipédia, est devenue unebase de référence pour le web des données. Les ressources peuvent y être répertoriéespar des catégories définies manuellement, dont la sémantique n'est pasdirectement accessible par des machines. Dans cet article, nous proposons deremédier à cette lacune au moyen de méthodes de fouille de données, à savoirla recherche de règles d'associations et de motifs apparentés. Nous présentonsune étude comparative de ces variantes sur une partie de DBpédia et discutonsle potentiel des différentes approches.;Justine Reynaud, Esther Galbrun, Mehwish Alam, Yannick Toussaint, Amedeo Napoli;http://editions-rnti.fr/render_pdf.php?p1&p=1002398;http://editions-rnti.fr/render_pdf.php?p=1002398;8;Paris;48.8555;2.3509
1282;Revue des Nouvelles Technologies de l'Information;EGC;2018;Détection de Singularités en temps-réel par combinaison d'apprentissage automatique et web sémantique basés sur Spark;;Badre Belabbess, Musab Bairat, Jérémy Lhez, Olivier Curé;http://editions-rnti.fr/render_pdf.php?p1&p=1002408;http://editions-rnti.fr/render_pdf.php?p=1002408;11;Paris;48.8556;2.3510
1283;Revue des Nouvelles Technologies de l'Information;EGC;2018;Echantillonnage de motifs séquentiels sous contrainte sur la norme;L'échantillonnage de motifs est une méthode non-exhaustive pour découvrir des motifs pertinents qui assure une bonne interactivité tout en offrant des garanties statistiques fortes grâce à sa nature aléatoire. Curieusement, une telle approche explorée pour les motifs ensemblistes et les sous-graphes ne l'a pas encore été pour les données séquentielles. Dans cet article, nous proposons la première méthode d'échantillonnage de motifs séquentiels. Outre le passage aux séquences, l'originalité de notre approche est d'introduire une contrainte sur la norme pour maîtriser la longueur des motifs tirés et éviter l'écueil de la « longue traîne ». Nous démontrons que notre méthode fondée sur une procédure aléatoire en deux étapes effectue un tirage exact. Malgré le recours à un échantillonnage avec rejet, les expérimentations montrent qu'elle reste performante.;Lamine Diop, Cheikh Talibouya Diop, Arnaud Giacometti, Dominique Li, Arnaud Soulet;http://editions-rnti.fr/render_pdf.php?p1&p=1002367;http://editions-rnti.fr/render_pdf.php?p=1002367;3;Paris;48.8557;2.3511
1284;Revue des Nouvelles Technologies de l'Information;EGC;2018;eDOI : exploration itérative de grands graphes multi-couches basée sur une mesure de l'intérêt de l'utilisateur;;Antoine Laumond, Norbert Feron, Guy Melançon, Bruno Pinaud;http://editions-rnti.fr/render_pdf.php?p1&p=1002410;http://editions-rnti.fr/render_pdf.php?p=1002410;11;Paris;48.8558;2.3512
1285;Revue des Nouvelles Technologies de l'Information;EGC;2018;Elaboration et utilisation d'une base de connaissances d'un domaine technique.;Ce poster rend compte d'une entreprise d'élaboration d'un système de représentation des connaissances pour le domaine géotechnique.;Nicolas Faure, René-Michel Faure;http://editions-rnti.fr/render_pdf.php?p1&p=1002404;http://editions-rnti.fr/render_pdf.php?p=1002404;11;Paris;48.8559;2.3513
1286;Revue des Nouvelles Technologies de l'Information;EGC;2018;Élimination des liens inter-langues erronés dans Wikipédia;Un lien inter-langue dans Wikipédia est un lien qui mène d'un articleappartenant à une édition linguistique à un autre article décrivant le mêmeconcept dans une autre langue. Ces liens sont ajoutés manuellement par les utilisateursdeWikipédia et ainsi ils sont susceptibles d'être erronés. Dans ce papier,nous proposons une approche pour l'élimination automatique des liens interlangues.Le principe de base est que la présence d'un lien erroné est révélée parl'existence d'un chemin de liens inter-langues reliant deux articles appartenant àune même édition linguistique. Notre approche élimine des liens inter-langues,à partir de ceux qui ont un faible score de correction, jusqu'à ce qu'il n'y aitplus de chemins entre deux articles d'une même édition linguistique. Les résultatsde notre évaluation sur un sous-graphe deWikipédia consistant en 8 languesmontre que l'approche est prometteuse.;Nacéra Bennacer Seghouani, Francesca Bugiotti, Jorge Galicia, Mariana Patricio, Gianluca Quercini;http://editions-rnti.fr/render_pdf.php?p1&p=1002417;http://editions-rnti.fr/render_pdf.php?p=1002417;7;Paris;48.8560;2.3514
1287;Revue des Nouvelles Technologies de l'Information;EGC;2018;Et si les réseaux sociaux pouvaient nous aider dans nos choix de carrière?;Dans cet article, nous présentons une méthode d'analyse de corpusafin de générer deux interfaces originales de visualisation dans le domaine del'e-recrutement. Notre approche s'appuie sur des millions de profils issus deplusieurs réseaux sociaux et sur des milliers d'offres d'emploi collectées surInternet. Nous décrivons dans ces travaux les étapes nécessaires pour leur réalisation.La première visualisation est une carte dynamique indiquant les métiersqui recrutent, dans quel domaine, dans quelle région tandis que la seconde meten avant les parcours professionnels et permet d'observer les perspectives ainsique les antécédents à plus ou moins long terme pour chaque métier considéré.;Rémy Kessler, Guy Lapalme, Fabrizio Gotti, Abdessamad Outerqiss, Philippe Langlais;http://editions-rnti.fr/render_pdf.php?p1&p=1002391;http://editions-rnti.fr/render_pdf.php?p=1002391;7;Paris;48.8561;2.3515
1288;Revue des Nouvelles Technologies de l'Information;EGC;2018;Étiquetage thématique automatisé de corpus par représentation sémantique;Dans les corpus de textes scientifiques, certains articles issus de communautésde chercheurs différentes peuvent ne pas être décrits par les mêmesmots-clés alors qu'ils partagent la même thématique. Ce phénomène cause desproblèmes dans la recherche d'information, ces articles étant mal indexés, etlimite les échanges potentiellement fructueux entre disciplines scientifiques.Notre modèle permet d'attribuer automatiquement une étiquette thématique auxarticles au moyen d'un apprentissage des représentations sémantiques d'articlesdu corpus déjà étiquetés. Passant bien à l'échelle, cette méthode a pu être testéesur une bibliothèque numérique d'articles scientifiques comportant des millionsde documents. Nous utilisons un réseau sémantique de synonymes pour extrairedavantage d'articles sémantiquement similaires et nous les fusionnons avec ceuxobtenus par un modèle de classement thématique. Cette méthode combinée présentede meilleurs taux de rappel que les versions utilisant soit le réseau sémantiqueseul, soit la seule représentation sémantique des textes.;Lucie Martinet, Hussein T. Al-Natsheh, Fabien Rico, Fabrice Muhlenbach, Djamel A. Zighed;http://editions-rnti.fr/render_pdf.php?p1&p=1002396;http://editions-rnti.fr/render_pdf.php?p=1002396;8;Paris;48.8562;2.3516
1289;Revue des Nouvelles Technologies de l'Information;EGC;2018;Évaluation comparative d'algorithmes de centralité pour la détection d'influenceurs;;Kévin Deturck, Damien Nouvel, Frédérique Segond;http://editions-rnti.fr/render_pdf.php?p1&p=1002405;http://editions-rnti.fr/render_pdf.php?p=1002405;11;Paris;48.8563;2.3517
1290;Revue des Nouvelles Technologies de l'Information;EGC;2018;Exploration et analyses multi-objectifs de séries temporelles de données météorologiques;Cet article présente les investigations menées sur les donnéesmesurées par des capteurs positionnés dans cinq villes de l'île de laRéunion. Des analyses exploratoires préalables permettent de comparer lescaractéristiques statistiques des villes considérées relativement aux différentesvariables météorologiques mesurées (flux solaires diffus et global, pressionatmosphérique, humidité, température, force et direction du vent). Nousappliquons diverses transformations sur les données avant d'analyser les sériesunivariées ou multivariées agrégées au pas de l'heure ou de la journée afin deconstruire des modèles de prédiction. Une approche classique de clusteringde séries temporelles est testée. Deux algorithmes de biclustering appliquéssuccessivement ont permis de grouper les journées d'observations partageantdes paramètres météorologiques horaires. Une caractérisation des biclusters, unevisualisation calendaire de leur succession ainsi qu'une recherche de séquencesfréquentes permettent d'exploiter les résultats et de faciliter leur interprétation.;Yelen Per, Kevin Dalleau, Malika Smail-Tabbone;http://editions-rnti.fr/render_pdf.php?p1&p=1002421;http://editions-rnti.fr/render_pdf.php?p=1002421;9;Paris;48.8564;2.3518
1291;Revue des Nouvelles Technologies de l'Information;EGC;2018;Extraction de chaînes cohérentes en vue de reconstuire la Trajectoire de l'information;Sur Internet, l'information se propage en particulier au travers des documentstextuels. Cette propagation soulève de nombreux défis : identifier uneinformation, suivre son évolution dans le temps, comprendre les mécanismes quirégissent sa propagation, etc. Étant donné un document parmi un grand corpusdans lequel de nombreuses informations circulent, pouvons-nous retrouver leschemins empruntés par l'information pour arriver à ce document ? Nous proposonsde définir la notion de trajectoire comme l'ensemble des chemins le longdesquels de l'information s'est propagée et nous proposons une méthode pourl'estimer. Nous avons mis en oeuvre une évaluation humaine pour juger de laqualité des chemins calculés. Nous montrons que les évaluations concordent laplupart du temps et que notre algorithme est efficace pour retrouver les bonschemins.;Charles Huyghues-Despointes, Leila Khouas, Julien Velcin, Sabine Loudcher;http://editions-rnti.fr/render_pdf.php?p1&p=1002395;http://editions-rnti.fr/render_pdf.php?p=1002395;7;Paris;48.8565;2.3519
1292;Revue des Nouvelles Technologies de l'Information;EGC;2018;Extraction de connaissances sur les défaillances de compteurs d'essieux;Cet article propose une méthode d'analyse pour des enregistrementsopérationnels d'un ensemble de compteurs d'essieux, qui constituent un élémentcentral à l'infrastructure ferroviaire. Notre objectif est de fournir une façon efficaced'extraire automatiquement des éléments de connaissance concernant lesdéfaillances de ces systèmes.Puisque les données fournies ne contiennent pas de vérité de terrain sur lescauses de défaillances, les informations et leurs causes doivent être extraites desrelations sous-tendant les événements enregistrés. Après une phase de prétraitement,les événements sont groupés en fonction des relations qui ont été misesen lumière entre eux. Ces regroupements peuvent ensuite être utilisés pour créerdes classes d'événements en utilisant un système de classification adapté.Au delà de cette application spécifique, cette approche est une façon nouvelled'aborder les problèmes d'analyse de fiabilité.;Iwo Doboszewski, Simon Fossier, Christophe Marsala;http://editions-rnti.fr/render_pdf.php?p1&p=1002394;http://editions-rnti.fr/render_pdf.php?p=1002394;5;Paris;48.8566;2.3520
1293;Revue des Nouvelles Technologies de l'Information;EGC;2018;Fouille de Motifs Graduels Fermés Fréquents Sous Contrainte de la Temporalité;;Jerry Lonlac, Benjamin Négrevergne, Yannick Miras, Aude Beauger, Engelbert Mephu Nguifo;http://editions-rnti.fr/render_pdf.php?p1&p=1002412;http://editions-rnti.fr/render_pdf.php?p=1002412;11;Paris;48.8567;2.3521
1294;Revue des Nouvelles Technologies de l'Information;EGC;2018;Fouille de motifs temporels négatifs;Dans cet article nous étudions le problème de l'extraction de motifsfréquents contenant des événements positifs, des événements négatifs spécifiantl'absence d'événement ainsi que des informations temporelles sur le délai entreces événements. Nous définissons la sémantique de tels motifs et proposons laméthode NTGSP basée sur des approches de l'état de l'art. Les performancesde la méthode sont évaluées sur des données commerciales fournies par EDF(Électricité de France).;Katerina Tsesmeli, Manel Boumghar, Thomas Guyet, Rene Quiniou, Laurent Pierre;http://editions-rnti.fr/render_pdf.php?p1&p=1002386;http://editions-rnti.fr/render_pdf.php?p=1002386;3;Paris;48.8568;2.3522
1295;Revue des Nouvelles Technologies de l'Information;EGC;2018;Interrogation de données structurellement hétérogènes dans les bases de données orientées documents;Les systèmes orientés documents permettent de stocker tout docu-ment, quel que soit leur schéma. Cette flexibilité génère une potentielle hété-rogénéité des documents qui complexifie leur interrogation car une même entitépeut être décrite selon des schémas différents. Cet article présente une approched’interrogation transparente des systèmes orientés documents. Pour cela, nousproposons de générer un dictionnaire de façon automatique lors de l’insertiondes documents, et qui associe à chaque attribut tous les chemins permettant d’yaccéder. Ce dictionnaire permet de réécrire la requête utilisateur à partir de dis-jonctions de chemins afin de retrouver tous les documents quelles que soientleurs structures. Nos expérimentations montrent des coûts d’exécution de la re-quête réécrite largement acceptables comparés au coût d’une requête sur sché-mas homogènes.;Hamdi Ben Hamadou,  Faiza Ghozzi, André Péninou, Olivier Teste;http://editions-rnti.fr/render_pdf.php?p1&p=1002430;http://editions-rnti.fr/render_pdf.php?p=1002430;8;Paris;48.8569;2.3523
1296;Revue des Nouvelles Technologies de l'Information;EGC;2018;KTI-MOOC: un système de recommandation pour la personnalisation du processus d'échange d'informations dans les MOOCs;Afin d'aider les apprenants à tirer profit du MOOC (Massive OpenOnline Course) qu'ils suivent, nous proposons un outil pour recommander àchacun d'entre eux une liste ordonnée des “Apprenants leaders” capables dele soutenir durant son processus d'apprentissage. La phase de recommandationest basée sur une approche d'aide à la décision multicritère pour la prédictionpériodique des “Apprenants leaders”. Etant donnée l'hétérogénéité des profilsdes apprenants, nous recommandons à chacun d'entre eux les leaders appropriésà son profil en utilisant la distance euclidienne et le filtrage démographique.;Sarra Bouzayane, Inès Saad;http://editions-rnti.fr/render_pdf.php?p1&p=1002428;http://editions-rnti.fr/render_pdf.php?p=1002428;11;Paris;48.8570;2.3524
1297;Revue des Nouvelles Technologies de l'Information;EGC;2018;L'exploitation de données contextuelles pour la recommandation d'hôtels;Les systèmes de recommandation ont pour rôle d'aider les utilisateurssubmergés par la quantité d'information à faire de bons choix à partir de vastescatalogues de produits. Le déploiement de ces systèmes dans l'industrie hôtelièreest confronté à des contraintes spécifiques, limitant la performance des approchestraditionnelles. Les systèmes de recommandation d'hôtels souffrent enparticulier d'un problème de démarrage à froid continu à cause de la volatilitédes préférences des voyageurs et du changement de comportements en fonctiondu contexte. Dans cet article, nous présentons le problème de recommandationd'hôtels ainsi que ses caractéristiques distinctives. Nous proposons de nouvellesméthodes contextuelles qui prennent en compte les dimensions géographique ettemporelle ainsi que la raison du voyage, afin de générer les listes de recommandation.Nos expérimentations sur des jeux de données réels soulignent lacontribution des données contextuelles à l'amélioration de la qualité de recommandation.;Marie Al Ghossein, Talel Abdessalem, Anthony Barré;http://editions-rnti.fr/render_pdf.php?p1&p=1002390;http://editions-rnti.fr/render_pdf.php?p=1002390;3;Paris;48.8571;2.3525
1298;Revue des Nouvelles Technologies de l'Information;EGC;2018;L'ontologie OntoBiotope pour l'étude de la biodiversité microbienne;L'intégration des données hétérogènes en Sciences de la Vie est unsujet de recherche majeur. L'importance et le volume considérable des informationssur les milieux de vie des microorganismes dans tous les domaines telsque la santé, l'agriculture ou l'environnement justifie le développement de traitementsautomatisés. Nous proposons ici l'ontologie OntoBiotope dont nous décrivonsles principes de construction ainsi que des exemples d'utilisation pourl'annotation et l'indexation sémantique des habitats microbiens décrits en languenaturelle dans les documents scientifiques.;Claire Nédellec, Estelle Chaix, Robert Bossy, Louise Deléger, Sandra Dérozier, Jean-Baptiste Bohuon, Valentin Loux;http://editions-rnti.fr/render_pdf.php?p1&p=1002401;http://editions-rnti.fr/render_pdf.php?p=1002401;1;Paris;48.8572;2.3526
1299;Revue des Nouvelles Technologies de l'Information;EGC;2018;Long-range influences in (social) networks;;Ernesto Estrada;http://editions-rnti.fr/render_pdf.php?p1&p=1002361;http://editions-rnti.fr/render_pdf.php?p=1002361;13;Paris;48.8573;2.3527
1300;Revue des Nouvelles Technologies de l'Information;EGC;2018;Mainmise sur les médias et suivi de communautés dans les graphes dynamiques;Ce court article présente le design et l'utilisation d'un tableau de bordvisuel permettant d'explorer, questionner et comprendre l'évolution des communautésd'un graphe dynamique. L'exemple ayant motivé la conception et laréalisation de ce tableau de bord est celui d'un réseau d'affiliation des personnalitésprésentes dans les médias français. Le suivi de communautés s'avère utilepour cerner le biais potentiel induit de la co-présence répétée des mêmes personnalitésdans les émissions de radio et de télévision au cours du temps.;Haolin Ren, Marie-Luce Viaud, Guy Melançon;http://editions-rnti.fr/render_pdf.php?p1&p=1002423;http://editions-rnti.fr/render_pdf.php?p=1002423;11;Paris;48.8574;2.3528
1301;Revue des Nouvelles Technologies de l'Information;EGC;2018;Mean-shift : Clustering scalable et distribué;"Nous présentons dans ce papier un nouvel algorithme Mean-Shift utilisantles K-plus proches voisins pour la montée du gradient (NNMS : NearestNeighbours Mean Shift). Le coût computationnel intensif de ce dernier a longtempslimité son utilisation sur des jeux de données complexes où un partitionnementen clusters non ellipsoïdaux serait bénéfique. Or, une implémentationscalable de l'algorithme ne compense pas l'augmentation du temps d'exécutionen fonction de la taille du jeu de données en raison de sa complexité quadratique.Afin de pallier, ce problème nous avons introduit le ""Locality SensitiveHashing"" (LSH) qui est une approximation de la recherche des K-plus prochesvoisins ainsi qu'une règle empirique pour le choix du K. La combinaison de cesaméliorations au sein du NNMS offre l'opportunité d'un traitement pertinentaux problématiques du clustering appliquée aux données massives.";Gaël Beck, Hanane Azzag, Mustapha Lebbah, Tarn Duong;http://editions-rnti.fr/render_pdf.php?p1&p=1002420;http://editions-rnti.fr/render_pdf.php?p=1002420;8;Paris;48.8575;2.3529
1302;Revue des Nouvelles Technologies de l'Information;EGC;2018;Méta-analyse ordinale d'enquêtes d'opinion Application aux usages de l'Internet des objets en entreprise;La multiplicité des enquêtes d'opinion sur un même sujet nécessite la construction de synthèses qui agrègent les résultats obtenus dans des conditions indépendantes. Dans cet article, nous proposons une nouvelle approche ordinale de méta-analyse qui consiste à rechercher un ordre consensus qui rend compte « au mieux » des ordres partiels entre les modalités issus des résultats des différentes enquêtes. Nous modélisons ce problème par une variante d'une recherche d'un ordre médian sur les sommets d'un graphe orienté pondéré et nous développons un algorithme de séparation-évaluation pour le résoudre. Notre approche est appliquée sur un ensemble d'enquêtes internationales portant sur les motivations et les freins à l'intégration de l'Internet des Objets dans les entreprises.;Rostand Affogbolo, Claire Gauzente, Alain Guénoche, Pascale Kuntz;http://editions-rnti.fr/render_pdf.php?p1&p=1002365;http://editions-rnti.fr/render_pdf.php?p=1002365;8;Paris;48.8576;2.3530
1303;Revue des Nouvelles Technologies de l'Information;EGC;2018;Méthode basée sur les ensembles approximatifs pour l'apprentissage incrémental en présence des données déséquilibrées;Ce papier propose une méthode basée sur la théorie des ensembles approximatifset dédiée à l'apprentissage supervisé incrémental dans un contextede données déséquilibrées. Cette méthode consiste en trois phases : la constructiond'une table de décision, l'inférence d'un ensemble de règles de décisionet la classification de chaque action potentielle dans l'une des classes de décisionprédéfinies. La méthode MAI2P est validée dans le contexte des MOOCs(Massive Open Online Courses).;Sarra Bouzayane, Inès Saad;http://editions-rnti.fr/render_pdf.php?p1&p=1002393;http://editions-rnti.fr/render_pdf.php?p=1002393;2;Paris;48.8577;2.3531
1304;Revue des Nouvelles Technologies de l'Information;EGC;2018;Méthode d'Apprentissage pour Extraire les Localisations dans les MicroBlogs;;Thi-Bich-Ngoc Hoang, Josiane Mothe;http://editions-rnti.fr/render_pdf.php?p1&p=1002411;http://editions-rnti.fr/render_pdf.php?p=1002411;11;Paris;48.8578;2.3532
1305;Revue des Nouvelles Technologies de l'Information;EGC;2018;Modélisation des métadonnées d'un data lake en data vault;Avec l'avènement des mégadonnées, l'informatique décisionnelle adû trouver des solutions pour gérer des données de très grands volume et variété.Les lacs de données (data lakes) répondent à ces besoins du point du vuedu stockage, mais nécessitent la gestion de métadonnées adéquates pour garantirun accès efficace aux données. Sur la base d'un modèle multidimensionnelde métadonnées conçu pour un lac de données présentant un défaut d'évolutivitéde schéma, nous proposons l'utilisation d'un data vault pour traiter ceproblème. Pour montrer la faisabilité de cette approche, nous instancions notremodèle conceptuel de métadonnées en modèles logiques et physiques relationnelet orienté document. Nous comparons également les modèles physiques entermes de stockage et de temps de réponse aux requêtes sur les métadonnées.;Iuri D. Nogueira, Maram Romdhane, Jérôme Darmont;http://editions-rnti.fr/render_pdf.php?p1&p=1002385;http://editions-rnti.fr/render_pdf.php?p=1002385;8;Paris;48.8579;2.3533
1306;Revue des Nouvelles Technologies de l'Information;EGC;2018;NFB: protocole de Notarisation des Documents dans la Blockchain;;Haikel Megrahi, Nouha Omrane, Rakia Jaziri;http://editions-rnti.fr/render_pdf.php?p1&p=1002415;http://editions-rnti.fr/render_pdf.php?p=1002415;11;Paris;48.8580;2.3534
1307;Revue des Nouvelles Technologies de l'Information;EGC;2018;Nouveau Modèle de Sélection de Caractéristiques basé sur la Théorie des Ensembles Approximatifs pour les Données Massives;;Zaineb Chelly Dagdia, Christine Zarges, Gaël Beck, Mustapha Lebbah;http://editions-rnti.fr/render_pdf.php?p1&p=1002409;http://editions-rnti.fr/render_pdf.php?p=1002409;11;Paris;48.8581;2.3535
1308;Revue des Nouvelles Technologies de l'Information;EGC;2018;PALM: Un algorithme parallèle pour extraire des clusters de liens dans les réseaux sociaux;Dans cet article, nous nous intéressons à l'optimisation du processusde recherche de clusters de liens. Nous proposons en particulier l'algorithmePALM (Stattner et al., 2017), qui vise à améliorer l'efficacité du processus d'extractionpar l'exploration conjointe de plusieurs zones de l'espace de recherche.Ainsi, nous commençons par démontrer que l'espace des solutions forme untreillis de concepts. Nous proposons ensuite une approche qui explore en parallèleles branches de ce treillis tout en réduisant l'espace de recherche en s'appuyantsur différentes propriétés. Les bonnes performances de notre algorithmesont démontrées en le comparant avec l'algorithme d'extraction d'origine.;Erick Stattner, Reynald Eugenie, Martine Collard;http://editions-rnti.fr/render_pdf.php?p1&p=1002419;http://editions-rnti.fr/render_pdf.php?p=1002419;7;Paris;48.8582;2.3536
1309;Revue des Nouvelles Technologies de l'Information;EGC;2018;Peerus Review: Un outil de recherche d'experts scientifiques;Nous proposons un outil de recherche d'experts appliqué au mondeacadémique sur les données générées par l'entreprise DSRT dans le cadre de sonapplication Peerus 1. Un utilisateur soumet le titre, le résumé et optionnellementles auteurs et le journal de publication d'un article scientifique et se voit proposerune liste d'experts, potentiels reviewers de l'article soumis. L'algorithme derecherche est un système de votes reposant sur un modèle du langage entrainé àpartir d'un ensemble de plusieurs millions d'articles scientifiques. L'outil est accessibleà chacun sous la forme d'une application web intitulée Peerus Review 2.;Robin Brochier, Adrien Guille, Julien Velcin, Benjamin Rothan, François Di Cioccio;http://editions-rnti.fr/render_pdf.php?p1&p=1002426;http://editions-rnti.fr/render_pdf.php?p=1002426;11;Paris;48.8583;2.3537
1310;Revue des Nouvelles Technologies de l'Information;EGC;2018;PerForecast : un outil de prévision de l'évolution de séries temporelles pour le planning capacitaire;Nous présentons PerForecast, un outil qui vise à automatiser le processusde planning capacitaire en utilisant des données temporelles univariéeset des modèles prédictifs configurés automatiquement. L'objectif est d'anticiperles problèmes de dimensionnement dans les infrastructures d'Orange quiassurent la délivrance d'un service aux clients. Il s'agira par exemple de prévoirau plus « tôt » la surcharge d'un serveur, afin de commander en avance de nouvellesmachines (avant la détérioration du service considéré). Les démarches dedimensionnent et d'achat étant longues et coûteuses, plus elles sont effectuéestôt, meilleure sera la qualité de service.;Colin Leverger, Régis Marguerie, Vincent Lemaire, Thomas Guyet, Simon Malinowski;http://editions-rnti.fr/render_pdf.php?p1&p=1002424;http://editions-rnti.fr/render_pdf.php?p=1002424;11;Paris;48.8584;2.3538
1311;Revue des Nouvelles Technologies de l'Information;EGC;2018;Prédiction du Rayonnement Solaire par Apprentissage Automatique;Cet article décrit une approche flexible pour la prédiction à courtterme de variables météorologiques. En particulier, nous nous intéressons à laprédiction du rayonnement solaire à une heure. Cette tâche est d'une grandeimportance pratique dans l'optique d'optimiser les resources énergétiques solaires.Comme le défi EGC 2018 nous fournit des données météorologiques enregistréessur cinq sites géographiques de l'île de la Réunion, nous utilisons cesdonnées historiques comme base pour créer des modèles de prédiction, et noustestons la performance de ces modèles selon le site considéré. Après avoir décritnotre méthode de nettoyage de données et de normalisation, nous combinonsune méthode de sélection de variables basée sur les modèles ARIMA (AutoRegressiveIntegrated Moving Average) à l'utilisation de méthodes de régressiongénériques, telles que les arbres de régression et les réseaux de neurones.;Pierrick Bruneau, Philippe Pinheiro, Yoann Didry;http://editions-rnti.fr/render_pdf.php?p1&p=1002422;http://editions-rnti.fr/render_pdf.php?p=1002422;9;Paris;48.8585;2.3539
1312;Revue des Nouvelles Technologies de l'Information;EGC;2018;Prétraitement de données spatialement imprécises pour une classification supervisée basée sur les images satellitaires;Dans un problème de classification supervisée, les données d'apprentissageproviennent souvent d'inventaires acquis sur le terrain par des expertsdu domaine. Toutefois, la localisation de ces inventaires est approximative (enraison de la précision intrinsèque des GPS portables utilisés). Cette imprécisionspatiale est particulièrement problématique lorsque ces données sont utiliséespour entrainer un classifieur sur des images satellitaires très haute résolution(THR). En effet, la précision spatiale des inventaires peut être dans certains casbien inférieure à celles de ces images. Dans ce papier, nous proposons trois approchesvisant à améliorer la précision spatiale des données terrain via des prétraitements.Le principe est d'exploiter les images satellitaires THR disponiblespour corriger spatialement les données terrain. Nos expérimentations mettenten avant l'intérêt de ces pré-traitements sur un jeu de données constitué de 24inventaires d'habitats coralliens et une image satellitaire THR (WorldView-2).;Jannaï Tokotoko, Frédéric Flouvat, Claire Goiran, Laetitia Hédouin, Antoine Collin, Nazha Selmaoui-Folcher;http://editions-rnti.fr/render_pdf.php?p1&p=1002377;http://editions-rnti.fr/render_pdf.php?p=1002377;5;Paris;48.8586;2.3540
1313;Revue des Nouvelles Technologies de l'Information;EGC;2018;Prise en compte de la structure des documents pour une indexation performante;;Pascal Cuxac, Nicolas Kieffer;http://editions-rnti.fr/render_pdf.php?p1&p=1002403;http://editions-rnti.fr/render_pdf.php?p=1002403;11;Paris;48.8587;2.3541
1314;Revue des Nouvelles Technologies de l'Information;EGC;2018;Propositions pour améliorer une méthode de prédiction du succès d'une campagne de financement participatif;Le financement participatif est un mode de financement d'un projet faisant appel à un grand nombre de personnes qui a connu une forte croissance avec l'émergence d'Internet et des réseaux sociaux. Cependant plus de 60 % des projets ne sont pas financés, il est donc important de bien préparer sa campagne de financement. De plus, en cours de campagne, il est crucial d'avoir une estimation rapide de son succès afin de pouvoir réagir rapidement (restructuration, communication) : des outils de prédiction sont alors indispensables. Nous proposons dans cet article plusieurs pistes d'amélioration pour la prédiction du montant levé lors d'une campagne de financement participatif en utilisant l'algorithme k-NN. La première proposition consiste à utiliser un algorithme de clustering afin de segmenter l'ensemble d'apprentissage et faciliter le passage à l'échelle. La seconde proposition consiste à extraire des caractéristiques pertinentes depuis les séries temporelles et les informations sur les campagnes pour avoir une représentation vectorielle.;Alexandre Blansché, Xavier Mazur;http://editions-rnti.fr/render_pdf.php?p1&p=1002374;http://editions-rnti.fr/render_pdf.php?p=1002374;2;Paris;48.8588;2.3542
1315;Revue des Nouvelles Technologies de l'Information;EGC;2018;Qu'est-ce qu'un bon système d'apprentissage ? La réponse a évolué avec le temps. Et demain?;L'apprentissage automatique, pardon le « machine learning », a envahi la sphère médiatiquegrâce à des succès impressionnants comme la victoire d'une machine au Go, ou la promesse de véhicules autonomes arrivant très prochainement sur nos routes. De fait, tant l'exploitation des données massives que la production de code machine à partir de l'expérience de la machine plutôt que par des humains, met l'apprentissage automatique au coeur de l'intelligence artificielle. Très certainement cela signifie que nous savons répondre à la question « qu'est-ce qu'un bon système d'apprentissage ? » et qu'il ne nous reste plus qu'à en décliner la réponse pour obtenir des systèmes adaptés à chaque domaine applicatif. Pourtant, la réponse à cette question a profondément évolué au cours des 60 dernières années, au point que les publications sur l'apprentissage automatique d'il y a quelques décennies semblent venir d'une autre planète et ne sont d'ailleurs plus enseignés aux étudiants. Et ceci pas seulement parce que les connaissances passées seraient jugées obsolètes, mais parce qu'elles ne semblent pas pertinentes. Avons-nous donc raison ? Nos précurseurs avaient-ils tort ? Et nos successeurs nous citeront-ils dans leurs manuels ? Dans cette présentation, nous examinerons quelques moments clés de l'histoire de l'apprentissage automatique correspondant à des tournants dans la manière de considérer ce qu'est un bon système d'apprentissage. Et nous nous demanderons si nous vivons un autre moment charnière dans lequel changent notre perspective, la question que nous cherchons à résoudre dans nos recherches, les concepts manipulés et la manière d'écrire nos papiers.;Antoine Cornuéjols;http://editions-rnti.fr/render_pdf.php?p1&p=1002360;http://editions-rnti.fr/render_pdf.php?p=1002360;0;Paris;48.8589;2.3543
1316;Revue des Nouvelles Technologies de l'Information;EGC;2018;Recommendation-based Keyword Search over Relational Databases;Récemment, la recherche par mots-clés dans les bases de données relationnelles a suscité un intérêtgrandissant en raison de sa facilité d'utilisation. Bien que des recherches approfondies fussentdernièrement effectuées dans ce contexte, la plupart de ces recherches non seulement nécessitent unaccès préalable aux données, ce qui restreint leur applicabilité si cette condition n'est pas vérifiée,mais aussi renvoient des réponses très génériques. Cependant, fournir aux utilisateurs des réponsespersonnalisées est devenu plus que jamais nécessaire en raison de la surabondance de données quipeut déranger l'utilisateur. Le défi de retourner des réponses pertinentes et personnalisées qui satisfontles besoins des utilisateurs demeure. Inspiré par l'application réussie de la technique de filtragecollaboratif dans les systèmes de recommandation, nous proposons une nouvelle approche baséesur les mots-clés pour fournir aux utilisateurs des résultats personnalisés basés sur l'hypothèse queseulement une information sur le schéma de la base de données est disponible.;Haithem Ghorbel, Nouha Othman, Rim Faiz;http://editions-rnti.fr/render_pdf.php?p1&p=1002400;http://editions-rnti.fr/render_pdf.php?p=1002400;3;Paris;48.8590;2.3544
1317;Revue des Nouvelles Technologies de l'Information;EGC;2018;Reconnaissance et indexation automatique des registres de la chancellerie française (1300-1483);Les documents manuscrits sont parmi les témoins les plus importants de l'histoire européenne. Ces dernières années, d'importantes collections de manuscrits historiques ont été numérisées et mises à disposition du public et des chercheurs. Cependant, la richesse des informations qu'ils contiennent est encore largement inaccessible car seul les images et quelques méta-données sont disponibles. L'idéal pour les utilisateurs serait de pouvoir faire des recherches textuelles comme pour les livres imprimés modernes (https://books.google.fr/). Si les technologies d'analyse de documents historiques et de reconnaissance d'écriture manuscrite sont encore trop peu performantes pour permettre l'utilisation directe de la transcription brute, il est possible de mettre à la disposition des utilisateurs un moteur de recherche textuel basé sur une indexation automatique des images de documents manuscrits. Cette indexation se base sur une transcription automatique mais tire profit de la capacité de la machine à générer des hypothèses reconnaissance multiples et pondérées. Cette technologie a permis de rendre accessible pour la première fois à la recherchetextuelle les registres de la chancellerie royale française (1302 -1483), un des corpus de documents historiques les plus emblématiques pour la France, ouvrant ainsi la voie à de nouvelles méthodes de recherche en histoire : http://www.himanis.org/;Christopher Kermorvant;http://editions-rnti.fr/render_pdf.php?p1&p=1002364;http://editions-rnti.fr/render_pdf.php?p=1002364;0;Paris;48.8591;2.3545
1318;Revue des Nouvelles Technologies de l'Information;EGC;2018;Reframing for Non-Linear Dataset Shift;Les modèles de classification discriminante supposent que les données de formation et dedéploiement ont les mêmes distributions d'attributs de données. Ces modèles donnent des performancestrès variées lorsqu'ils sont déployés dans des conditions variées avec différentesdistributions de données. Ce phénomène est appelé Dataset Shift. Dans cet article, nous avonsfourni une méthode qui détermine d'abord s'il y a un changement significatif dans les distributionsd'attributs entre les ensembles de données d'apprentissage et de déploiement. S'ilexiste un changement dans les données, la méthode proposée utilise ensuite une approche deHill climbing pour cartographier ce décalage, quelle que soit sa nature, c'est-à-dire (linéaireou non linéaire) à l'équation pour la transformation quadratique. Les résultats expérimentauxsur trois jeux de données réels montrent de forts gains de performance obtenus par la méthodeproposée par rapport aux méthodes précédemment établies telles que le reconditionnement etle recadrage linéaire.;Md Shadman Rafid, Mohammad Mazedul Islam, Md Naimul Hoque, Chowdhury Farhan Ahmed;http://editions-rnti.fr/render_pdf.php?p1&p=1002375;http://editions-rnti.fr/render_pdf.php?p=1002375;2;Paris;48.8592;2.3546
1319;Revue des Nouvelles Technologies de l'Information;EGC;2018;Régression Laplacienne semi-supervisée pour la reconstitution des dates de pose des réseaux d'assainissement;La date de pose est souvent un facteur principal d'explication de la dégradationdes conduites d'assainissement. Pour les gestionnaires de ces réseaux,connaître cette information permet ainsi (par l'utilisation de modèles de détérioration)de prédire l'état de santé actuel des conduites non encore inspectées.Cette connaissance est primordiale pour prendre des décisions dans un contextede forte contrainte budgétaire. L'objectif est ainsi de reconstituer ces dates depose à partir des caractéristiques du patrimoine et de son environnement. Lesdonnées à manipuler présentent plusieurs niveaux de complexité importants.Leurs sources sont hétérogènes, leur volume est important et les informationssur leur étiquetage (dates) sont limitées : seulement 24 % du linéaire est connupour les réseaux d'assainissement de la métropole de Lyon. La base de donnéessous-jacente contient les caractéristiques connues des conduites (profil géométrique,matériau utilisé, etc.). Dans ce papier, nous proposons de mesurer l'effetet l'impact de quelques méthodes d'apprentissage statistique semi-supervisé, etde proposer ainsi une approche alternative adaptée à la reconstitution de ce typede données.;Vivien Kraus, Khalid Benabdeslem, Frederic Cherqui;http://editions-rnti.fr/render_pdf.php?p1&p=1002389;http://editions-rnti.fr/render_pdf.php?p=1002389;2;Paris;48.8593;2.3547
1320;Revue des Nouvelles Technologies de l'Information;EGC;2018;Réseau bayésien pour la gestion de l'obsolescence dans une base d'informations en vue de l'évaluation du risque de chute des personnes âgées;L'évaluation périodique du risque de chute des personnes âgéesrequiert des informations fiables et nombreuses. Comme il n'est pas possiblede recueillir régulièrement toutes ces informations, les observationssont faites au fil du temps et conservées, ce qui entraîne une problématiqueliée au vieillissement des informations. Cet article traite de la détectiondes informations obsolètes dans une base d'informations sur unepersonne âgée. Nous proposons une solution comportant un modèle deconnaissances sur les personnes âgées sous forme d'un réseau bayésien etun module de raisonnement chargé de la détection et de la gestion descontradictions et des doutes sur les informations.;Salma Chaieb, Véronique Delcroix, Ali Ben Mrad, Emmanuelle Grislin-Le Strugeon;http://editions-rnti.fr/render_pdf.php?p1&p=1002402;http://editions-rnti.fr/render_pdf.php?p=1002402;1;Paris;48.8594;2.3548
1321;Revue des Nouvelles Technologies de l'Information;EGC;2018;Savoir au dela de voir: vision artificielle et raisonnement logique;;Roberto Marroquin, Julien Dubois, Christophe Nicolle;http://editions-rnti.fr/render_pdf.php?p1&p=1002413;http://editions-rnti.fr/render_pdf.php?p=1002413;11;Paris;48.8595;2.3549
1322;Revue des Nouvelles Technologies de l'Information;EGC;2018;Sémantique des données d'observation en neuro-imagerie selon un point de vue réaliste;L'objectif de ce travail est de décrire avec une approche réaliste lasignification des données d'observation en neuro-imagerie sous un format formelpour faciliter leur interprétation par les cliniciens et leur réutilisation dansd'autres contextes.;Emna Amdouni, Bernard Gibaud;http://editions-rnti.fr/render_pdf.php?p1&p=1002399;http://editions-rnti.fr/render_pdf.php?p=1002399;1;Paris;48.8596;2.3550
1323;Revue des Nouvelles Technologies de l'Information;EGC;2018;Temporal hints in the cultural heritage discourse: what can an ontology of time as it is worded reveal?;Dans le champ des sciences patrimoniales, la dimension temporelle de l'information joueun rôle à l'évidence majeur tant pour l'interpréter et l'analyser que pour relier des faits isolés. Mais la façon dont cette dimension est verbalisée pose des problèmes de formalisation non triviaux. Pourtant, cette verbalisation, que l'on associe souvent au terme-chapeau d'incertitude, peut être lue en dissociant d'une part le caractère mal connu d'un fait documenté, irréductible, et les choix faits par le producteur de l'information pour la relativiser. Dans cette contribution nous proposons un modèle formel permettant d'observer et d'analyser de façon systématique cette couche de verbalisation. L'expérience est menée sur des données fortement hétérogènes, souvent d'origine citoyenne, documentant le petit patrimoine matériel et immatériel. Ce cas d'étude est donc limité, mais il apparait néanmoins comme portant une question de fond allant au-delà du cas d'espèce. La contribution détaille d'abord la grille d'analyse d'indices temporels proposée, puis relate l'expérimentation concrète associée (ontologie OWL). Il n'est pas fait état d'une quelconque prétention à un résultat généralisable stricto sensu, mais cette expérience peut contribuer à nourrir de façcon pragmatique un débat nécessaire sur la formalisation d'indices temporels dans les sciences historiques.;Gamze Saygi, Jean-Yves Blaise, Iwona Dudek;http://editions-rnti.fr/render_pdf.php?p1&p=1002370;http://editions-rnti.fr/render_pdf.php?p=1002370;7;Paris;48.8597;2.3551
1324;Revue des Nouvelles Technologies de l'Information;EGC;2018;Un modèle Bayésien de co-clustering de données mixtes;Nous proposons un modèle de co-clustering de données mixtes et uncritère Bayésien de sélection du meilleur modèle. Le modèle infère automatiquementles discrétisations optimales de toutes les variables et effectue un coclusteringen minimisant un critère Bayésien de sélection de modèle. Un avantagede cette approche est qu'elle ne nécessite aucun paramètre utilisateur. Deplus, le critère proposé mesure de façon exacte la qualité d'un modèle tout enétant régularisé. L'optimisation de ce critère permet donc d'améliorer continuellementles modèles trouvés sans pour autant sur-apprendre les données. Les expériencesréalisées sur des données réelles montrent l'intérêt de cette approchepour l'analyse exploratoire des grandes bases de données.;Aichetou Bouchareb, Marc Boullé, Fabrice Rossi, Fabrice Clérot;http://editions-rnti.fr/render_pdf.php?p1&p=1002388;http://editions-rnti.fr/render_pdf.php?p=1002388;2;Paris;48.8598;2.3552
1325;Revue des Nouvelles Technologies de l'Information;EGC;2018;Une approche sémantique hybride pour la recommandation des articles d'actualité à large échelle;Les portails d'actualités en ligne produisent un flux d'informationayant un volume et une vélocité importants. Dans ce contexte, il devient plusdifficile de proposer en temps réel des recommandations dynamiques adaptéesaux intérêts de chaque utilisateur. Dans cet article, nous présentons une approchehybride pour la recommandation des articles d'actualité reposant sur l'analysesémantique du contenu disponible. L'approche est basée sur l'hybridation deplusieurs approches personnalisées et non personnalisées pour remédier au problèmede démarrage à froid. L'expérimentation de notre approche dans un environnementà large échelle et à fortes contraintes temps réel dans le cadre duchallenge NEWSREEL a permis d'évaluer la qualité de ses recommandations etde confirmer l'apport de la sémantique dans le processus de recommandation.;Hemza Ficel, Mohamed Ramzi Haddad, Hajer Baazaoui Zghal;http://editions-rnti.fr/render_pdf.php?p1&p=1002392;http://editions-rnti.fr/render_pdf.php?p=1002392;3;Paris;48.8599;2.3553
1326;Revue des Nouvelles Technologies de l'Information;EGC;2018;Une méthode pour l'estimation désagrégée de données de population à l'aide de données ouvertes;Nous présentons dans ce travail une méthode de désagrégation pour l'estimation de population à l'échelle locale à partir de données ouvertes globales. Notre but est d'estimer notamment le nombre de personnes résidant dans chaque bâtiment de la zone d'intérêt, à partir de données à plus grande échelle. Une description fine à l'échelle résidentielle est tout d'abord effectuée à partir des données d'OpenStreetMap. Les surfaces des bâtiments d'habitation ou d'usage mixte (habitation et activités) sont notamment identifiées. Nous effectuons ensuite une désagrégation à partir de données de grille de population à grande échelle (1km2 par carreau), guidée par les surfaces des bâtiments compris dans chaque carreau de la grille. Ensuite, nous effectuons une désagrégation à partir de données de grille de population à grande échelle (1km2 par carreau), guidée par les distributions spatiales découvertes à l'étape précédente. Nous utilisons exclusivement des données ouvertes pour favoriser la réplicabilité et pour pouvoir appliquer notre méthode à toute région d'intérêt, pour peu que la qualité des données soit suffisante. L'évaluation et la validation du résultat dans le cas de plusieurs villes Françaises sont effectuées à l'aide de données de recensement INSEE.;Luciano Gervasoni, Serge Fenet, Peter Sturm;http://editions-rnti.fr/render_pdf.php?p1&p=1002371;http://editions-rnti.fr/render_pdf.php?p=1002371;5;Paris;48.8600;2.3554
1327;Revue des Nouvelles Technologies de l'Information;EGC;2018;UNITEX/GRAMLAB: plateforme libre basée sur des lexiques et des grammaires pour le traitement des corpus textuels;L'objectif de notre recherche est de répondre aux besoins croissants etdivers d'extraction d'information pertinente exprimés par de nombreuses disciplines.Nous utilisons pour cela l'analyseur multilingue de corpus Unitex/Gram-Lab développé à l'Université Paris-Est Marne-la-Vallée. Il fait appel à une approchesymbolique et utilise des ressources linguistiques, dictionnaires électroniqueset grammaires locales. Cette présentation ne constitue qu'une prise enmain d'Unitex/GramLab et ne reflète que très partiellement les possibilités dulogiciel et son champ d'utilisation, notamment pour l'extraction d'information,qui s'étend du monde de la recherche à celui de l'industrie.;Tita Kyriacopoulou, Claude Martineau, Cristian Martinez;http://editions-rnti.fr/render_pdf.php?p1&p=1002427;http://editions-rnti.fr/render_pdf.php?p=1002427;11;Paris;48.8601;2.3555
1328;Revue des Nouvelles Technologies de l'Information;EGC;2018;Universal-endpoint.com : une plateforme d'accès simple au Web des Données;Universal-endpoint.com est une plateforme web permettant un accèssimple au Web des Données par trois aspects : (i) une plateforme de correspondance,pour l'accès aux bases du Web des Données depuis un seul point d'accèscentralisé, (ii) le langage SimplePARQL, pour une écriture intuitive de requêtessous forme de triplets à la manière de SPARQL mais ne nécessitant pas uneconnaissance préalable des bases du Web des Données, et (iii) une aide à larédaction de requêtes SPARQL.;Thomas Raimbault, Abdellah Sabry, Sonia Djebali;http://editions-rnti.fr/render_pdf.php?p1&p=1002429;http://editions-rnti.fr/render_pdf.php?p=1002429;11;Paris;48.8602;2.3556
1329;Revue des Nouvelles Technologies de l'Information;EGC;2018;Utilisation de techniques de modélisation thématiques pour la détection de nouveauté dans des flux de données textuelles.;Avec l'avènement des réseaux sociaux et la multiplication des messagesproduits au sujet des entreprises, mieux comprendre les retours clients estdevenu un enjeu primordial. Des techniques de classification automatique et demodélisation thématique permettent d'ors déjà d'observer les principales tendancesobservées dans ces données. Il est intéressant, dans une optique d'anticipation,d'observer les thématiques émergentes et de les identifier avant qu'ellesne prennent de l'ampleur. Afin de résoudre cette problématique, nous avons étudiéla piste de l'utilisation de modèles LDA pour détecter les documents relatifsà ces thématiques émergentes. Nous avons testé trois systèmes sur plusieurs scénariosd'arrivées de la nouveauté dans le flux de données. Nous montrons queles modèles thématiques permettent de détecter cette nouveauté mais que celadépend du scénario envisagé.;Clément Christophe, Julien Velcin, Manel Boumghar;http://editions-rnti.fr/render_pdf.php?p1&p=1002383;http://editions-rnti.fr/render_pdf.php?p=1002383;1;Paris;48.8603;2.3557
1330;Revue des Nouvelles Technologies de l'Information;EGC;2018;Visualisation dynamique de connaissances : application aux interactions entre facteurs de risque des maladies cardiovasculaires;;Rabia Azzi, Sylvie Desprès, Jérôme Nobécourt;http://editions-rnti.fr/render_pdf.php?p1&p=1002407;http://editions-rnti.fr/render_pdf.php?p=1002407;11;Paris;48.8604;2.3558
